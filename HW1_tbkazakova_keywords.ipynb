{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy-udpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'ru' language\n"
     ]
    }
   ],
   "source": [
    "import RAKE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "from summa import keywords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "import collections\n",
    "import spacy_udpipe\n",
    "spacy_udpipe.download(\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')\n",
    "stop.extend(['который', 'оно', 'весь', 'это', 'оба', 'ещё', 'свой', 'очень', 'затем', 'каков', 'наш', 'вкупе', 'например',\n",
    "             'возможно', 'увы', 'примерно', 'некоторый', 'кстати', 'именно', 'лишь', 'вроде', 'вовсе', 'каждый', 'поскольку',\n",
    "             'вполне', 'либо', 'нея', 'поэтому', '—', 'довольно', 'столь', 'что'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лемматизация текстов\n",
    "m = MorphAnalyzer()\n",
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(\n",
    "            m.parse(t)[0].normal_form\n",
    "        )\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Миникорпус состоит из 9 новостей с сайта http://astro.uni-altai.ru/.\n",
    "\n",
    "После текста новости даются ключевые слова. Написано: \"Ключевые слова: ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Я разметила ключевые слова. Эталоном стало объединение двух списков.\n",
    "\n",
    "В файликах с текстами перед содержанием есть абзац с ключевыми словами от сайта и с эталонными (=их+мои)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получили корпус из файликов\n",
    "all_kws = []\n",
    "all_texts = []\n",
    "for i in range(9):\n",
    "    filename = 'HW1_keywords_corpus/' + str(i+1) + '.txt'\n",
    "    with open(filename, encoding='utf8') as f:\n",
    "        info = f.readlines()\n",
    "        kw = info[2].strip().split(': ')[1].split(', ')\n",
    "        text = info[4:]\n",
    "        text = ''.join(text)\n",
    "    all_kws.append(kw)\n",
    "    all_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['галактика',\n",
       "  'тёмный материя',\n",
       "  'тёмный вещество',\n",
       "  'sdss',\n",
       "  'карликовый галактика',\n",
       "  'спутниковый галактика',\n",
       "  'спутник',\n",
       "  'карлик',\n",
       "  'млечный путь',\n",
       "  'василий белокуров',\n",
       "  'слоановский цифровой обзор небо'],\n",
       " ['планет',\n",
       "  'экзопланет',\n",
       "  'субар',\n",
       "  'кек',\n",
       "  'hires',\n",
       "  'hat-p-7b',\n",
       "  'ретроградный орбита',\n",
       "  'обратный орбита',\n",
       "  'вращение'],\n",
       " ['планет',\n",
       "  'экзопланет',\n",
       "  'ядро',\n",
       "  'обитаемый зона',\n",
       "  'планетарный ядро',\n",
       "  'магнитный пол',\n",
       "  'обитание'],\n",
       " ['земля',\n",
       "  'полярный сияние',\n",
       "  'магнитный полюс',\n",
       "  'сибирь',\n",
       "  'аляска',\n",
       "  'движение',\n",
       "  'канада'],\n",
       " ['сатурн',\n",
       "  'cassini',\n",
       "  'полярный сияние',\n",
       "  'aurora',\n",
       "  'uvis',\n",
       "  'кассинь',\n",
       "  'сияние'],\n",
       " ['ракета', 'солнечный парус', 'institute of space', 's-310-34', 'космос'],\n",
       " ['солнечный система',\n",
       "  'галактика',\n",
       "  'млечный путь',\n",
       "  'квазар',\n",
       "  'параллакс',\n",
       "  'w3oh',\n",
       "  'спиральный рукав',\n",
       "  'тригонометрический параллакс',\n",
       "  'расстояние'],\n",
       " ['hubble', 'галактика', 'vlt', 'квазар', 'чёрный дыра'],\n",
       " ['солнечный система',\n",
       "  'астрономия',\n",
       "  'пояс койперо',\n",
       "  'планетоид',\n",
       "  'двойной планет',\n",
       "  'гравитационный связанный',\n",
       "  'qw322']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Нормализуем кс так, как мы их будем получать от методов\n",
    "all_kws_norm = []\n",
    "for kws in all_kws:\n",
    "    all_kws_norm.append(list(map(normalize_text, kws)))\n",
    "all_kws_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "#### Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня всего два \"ключевых слова\" длиннее двух слов, поэтому было решено сделать maxWords=2, чтобы много лишних сочетаний не попадало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['оставаться незамеченный',\n",
       "  'несколько сотня',\n",
       "  'таинственный материя',\n",
       "  'обнаруживаться исключительно',\n",
       "  'гравитационный взаимодействие',\n",
       "  'обычный вещество',\n",
       "  'светов луч',\n",
       "  'относиться непосредственно',\n",
       "  'точный классификация',\n",
       "  'должный содержаться',\n",
       "  'участок небо',\n",
       "  'окружающий область',\n",
       "  'соответствующий статья',\n",
       "  'astrophysical journal',\n",
       "  'имя созвездие',\n",
       "  'волос вероника',\n",
       "  'левый iv',\n",
       "  'четвёрка находиться',\n",
       "  'самый мелкий',\n",
       "  'подобно большинство',\n",
       "  'скорее хоббит',\n",
       "  'шутить белокуров',\n",
       "  'русский перевод',\n",
       "  'исследователь смочь',\n",
       "  'маленькая спутник',\n",
       "  'туманность андромеда',\n",
       "  'умудриться заглотить',\n",
       "  'протогалактический фрагмент',\n",
       "  'самый известный',\n",
       "  'левый i',\n",
       "  'левый ii',\n",
       "  'малый медведица',\n",
       "  'изображение m',\n",
       "  'daniel zucker',\n",
       "  'речь идти',\n",
       "  'белокуров назвать',\n",
       "  'отбросить окончание',\n",
       "  'содержаться большой',\n",
       "  'большой пёс',\n",
       "  'большой часть',\n",
       "  'общий количество',\n",
       "  'данные sdss',\n",
       "  'точнее оценить',\n",
       "  'удаться найти',\n",
       "  'гораздо слабый',\n",
       "  'галактический центр',\n",
       "  'карликовый галактика',\n",
       "  'собственно звезда',\n",
       "  'называть карлик',\n",
       "  'обнаружить sdss',\n",
       "  'галактика крупный',\n",
       "  'большой',\n",
       "  'sdss',\n",
       "  'количество'],\n",
       " ['hat-p-7b',\n",
       "  'результат наблюдение',\n",
       "  'процесс сближение',\n",
       "  'американский коллега',\n",
       "  'сайт arxiv',\n",
       "  'материал newscientist',\n",
       "  'день назад'],\n",
       " ['linda elkins-tanton',\n",
       "  'сара сигера',\n",
       "  'sara seager',\n",
       "  'пока несколько',\n",
       "  'обитаемый зона',\n",
       "  'вершина айсберг',\n",
       "  'элкинс-тэнтон',\n",
       "  'ряд случай',\n",
       "  'радиоактивный нагрев',\n",
       "  'вязкий мантия',\n",
       "  'внутренний твёрдый',\n",
       "  'внешний жидкий',\n",
       "  'скалистый планет',\n",
       "  'значительный расстояние',\n",
       "  'создавать окись',\n",
       "  'минерал ранний',\n",
       "  'успеть спуститься',\n",
       "  'магнитный поль',\n",
       "  'космический луч',\n",
       "  'вопрос пригодность',\n",
       "  'нравиться думать',\n",
       "  'железный ядро',\n",
       "  'отсутствие ядро',\n",
       "  'мочь существовать',\n",
       "  'жизнь далеко',\n",
       "  'защищать жизнь',\n",
       "  'жизнь намного',\n",
       "  'скалистый мир',\n",
       "  'образ оказаться',\n",
       "  'ядро мочь',\n",
       "  'внешне сходный',\n",
       "  'толща планета',\n",
       "  'центр планета',\n",
       "  'формироваться ядро',\n",
       "  'ядро',\n",
       "  'мочь',\n",
       "  'жизнь'],\n",
       " ['северный америка',\n",
       "  'мочь оказаться',\n",
       "  'заявлять учёный',\n",
       "  'аляска большой',\n",
       "  'стать интенсивный',\n",
       "  'северный европа',\n",
       "  'магнитный полюс',\n",
       "  'сдвиг происходить',\n",
       "  'сан-франциско',\n",
       "  'слово исследователь',\n",
       "  'миграция увеличиться',\n",
       "  'последний столетие',\n",
       "  'учёный сделать',\n",
       "  'арктический озеры',\n",
       "  'полюс мигрировать'],\n",
       " ['ультрафиолетовый диапазон',\n",
       "  'полюс сатурн',\n",
       "  'человеческий глаз',\n",
       "  'фотография видно',\n",
       "  'оттенок красный',\n",
       "  'небольшой различие',\n",
       "  'полярный область',\n",
       "  'синтезировать изображение',\n",
       "  'видный вспышка',\n",
       "  'сделать cassini',\n",
       "  'левый снимка'],\n",
       " ['развёртывание первое',\n",
       "  'борт сразу',\n",
       "  'отличаться форма',\n",
       "  'шестью лепесток',\n",
       "  'планетарный общество',\n",
       "  'planetary society',\n",
       "  'пробовать запускать',\n",
       "  'эксперимент провалиться',\n",
       "  'упасть вместе',\n",
       "  'полёт пока',\n",
       "  'качество первое',\n",
       "  'эксперимент предназначаться',\n",
       "  'каковой фактически',\n",
       "  'сообщать membrana',\n",
       "  'экспериментальный парус',\n",
       "  'круглый парус',\n",
       "  'солнечный парус',\n",
       "  'успешно развернуть',\n",
       "  'аппарат создать',\n",
       "  'космос российский',\n",
       "  'парус'],\n",
       " ['спиральный рукав',\n",
       "  'солнечный система',\n",
       "  'считаться ранее',\n",
       "  'ye xu',\n",
       "  'видимый блеск',\n",
       "  'обозначать w3oh',\n",
       "  'голубой сверхгигант',\n",
       "  'получить что-',\n",
       "  'сильно зависеть',\n",
       "  'мочь приводить',\n",
       "  'значительный ошибка',\n",
       "  'подобно солнце',\n",
       "  'эффект доплера',\n",
       "  'гораздо точнее',\n",
       "  'астроном воспользоваться',\n",
       "  'режим радиоинтерферометр',\n",
       "  'сверхдлинный база',\n",
       "  'единый инструмент',\n",
       "  'разрешение инструмент',\n",
       "  'удаться определить',\n",
       "  'называть пекулярный',\n",
       "  'немного против',\n",
       "  'галактический диск',\n",
       "  'журнал science',\n",
       "  'начало январь',\n",
       "  'собираться останавливаться',\n",
       "  'определить расстояние',\n",
       "  'определять расстояние',\n",
       "  'определение расстояние',\n",
       "  'измерять расстояние',\n",
       "  'земля двигаться',\n",
       "  'угловой секунда',\n",
       "  'слишком надёжный',\n",
       "  'результат опубликовать',\n",
       "  'скорость определяться',\n",
       "  'вели наблюдение',\n",
       "  'оценка расстояние',\n",
       "  'далёкий объект',\n",
       "  'расстояние определённый',\n",
       "  'спектр звезда',\n",
       "  'расстояние'],\n",
       " ['квазар-одиночка he0450-2958',\n",
       "  'подозрительно похожий',\n",
       "  'лишить окружающий',\n",
       "  'поставить астроном',\n",
       "  'тёмный материя',\n",
       "  'превышать яркость',\n",
       "  'просто затмевать',\n",
       "  'собственный свет',\n",
       "  'john bahcall',\n",
       "  'принстонский университет',\n",
       "  'нью-джерси',\n",
       "  'журнал nature',\n",
       "  'уникальный феномен',\n",
       "  'pierre magain',\n",
       "  'льежский университет',\n",
       "  'чёрный дыра',\n",
       "  'пример квазар',\n",
       "  'квазар видный',\n",
       "  'яркость квазар',\n",
       "  'обычный квазар',\n",
       "  'космос объект',\n",
       "  'объект состоять',\n",
       "  'образ поддерживаться',\n",
       "  'объём вещество',\n",
       "  'родной галактика',\n",
       "  'гипотетический галактика',\n",
       "  'квазар',\n",
       "  'квазар —',\n",
       "  'объект'],\n",
       " ['jean-marc petit',\n",
       "  'рекордно большой',\n",
       "  'исследовательский группа',\n",
       "  'период обращение',\n",
       "  'плоскость эклиптика',\n",
       "  'обладать малое',\n",
       "  'порядок большой',\n",
       "  'групповой объект',\n",
       "  'устойчивый пара',\n",
       "  'иметь аналог',\n",
       "  'пояс астероид',\n",
       "  'открытие свидетельствовать',\n",
       "  'труд разрушить',\n",
       "  'компонента мочь',\n",
       "  'гравитационный сила',\n",
       "  'мочь возникнуть',\n",
       "  'результат столкновение',\n",
       "  'однако сразу',\n",
       "  'орбита компонент',\n",
       "  'разделить компонент',\n",
       "  'удалённый друг',\n",
       "  'километр друг',\n",
       "  'компонент']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rake_kw = []\n",
    "for i in range(9):\n",
    "    rake_kw_list = []\n",
    "    rake_kw_res = rake.run(normalize_text(all_texts[i]), maxWords=2, minFrequency=1)\n",
    "    for res in rake_kw_res:\n",
    "        if res[1] > 1.5:\n",
    "            rake_kw_list.append(res[0])\n",
    "    all_rake_kw.append(rake_kw_list)\n",
    "all_rake_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['год',\n",
       "  'обнаружить',\n",
       "  'sdss',\n",
       "  'карликовый галактика найти хоббит астроном',\n",
       "  'большой',\n",
       "  'новое спутник',\n",
       "  'галактический',\n",
       "  'млечный путь',\n",
       "  'самый',\n",
       "  'скопление',\n",
       "  'спутников'],\n",
       " ['орбита',\n",
       "  'вращение',\n",
       "  'наблюдение',\n",
       "  'учёный',\n",
       "  'американский',\n",
       "  'японский',\n",
       "  'hat',\n",
       "  'of',\n",
       "  'телескоп',\n",
       "  'the',\n",
       "  'звезда',\n",
       "  'специалист',\n",
       "  'arxiv',\n",
       "  'превосходить',\n",
       "  'транзитный',\n",
       "  'наклон',\n",
       "  'период чрезвычайно',\n",
       "  'результат',\n",
       "  'использоваться',\n",
       "  'использовать',\n",
       "  'ося',\n",
       "  'ось'],\n",
       " ['ядро мочь',\n",
       "  'планета',\n",
       "  'планет',\n",
       "  'мир',\n",
       "  'зона',\n",
       "  'формирование',\n",
       "  'образ',\n",
       "  'сигера',\n",
       "  'пока',\n",
       "  'создаваться',\n",
       "  'создавать',\n",
       "  'различный',\n",
       "  'успеть',\n",
       "  'условие',\n",
       "  'ряд',\n",
       "  'жизнь далеко',\n",
       "  'мантия',\n",
       "  'жидкий вода'],\n",
       " ['северный',\n",
       "  'магнитный полюс',\n",
       "  'год',\n",
       "  'мочь',\n",
       "  'учёный',\n",
       "  'нормальный',\n",
       "  'государственный',\n",
       "  'меняться',\n",
       "  'изучение образцов',\n",
       "  'заявить джозеф',\n",
       "  'американский геофизический'],\n",
       " ['сияние',\n",
       "  'солнечный',\n",
       "  'снимка',\n",
       "  'ультрафиолетовый диапазон',\n",
       "  'экспедиция',\n",
       "  'изображение',\n",
       "  'видный',\n",
       "  'видно',\n",
       "  'авроральный',\n",
       "  'полярный',\n",
       "  'голубой кольцо',\n",
       "  'cassini',\n",
       "  'uvis'],\n",
       " ['аппарат',\n",
       "  'солнечный парус развернуть',\n",
       "  'год',\n",
       "  'космос',\n",
       "  'космический агентство',\n",
       "  'земля японский институт',\n",
       "  'membrana',\n",
       "  'первое',\n",
       "  'полимерный плёнка',\n",
       "  'российский',\n",
       "  'бабакина',\n",
       "  'август'],\n",
       " ['расстояние',\n",
       "  'астрономический',\n",
       "  'скорость',\n",
       "  'измерить параллакс рукав галактика',\n",
       "  'звезда',\n",
       "  'надёжный метод',\n",
       "  'определение',\n",
       "  'определённый',\n",
       "  'измерять',\n",
       "  'область',\n",
       "  'звездообразование',\n",
       "  'измерение координата объект'],\n",
       " ['квазар',\n",
       "  'галактика',\n",
       "  'he',\n",
       "  'объект',\n",
       "  'университет',\n",
       "  'группа астроном',\n",
       "  'уникальность',\n",
       "  'уникальный',\n",
       "  'телескоп',\n",
       "  'чёрный дыра',\n",
       "  'светов год',\n",
       "  'пузырь',\n",
       "  'свет'],\n",
       " ['объект',\n",
       "  'компонент',\n",
       "  'компонента',\n",
       "  'гравитационный',\n",
       "  'масса',\n",
       "  'койперо обнаружить',\n",
       "  'составлять',\n",
       "  'малое',\n",
       "  'малый',\n",
       "  'большой',\n",
       "  'год',\n",
       "  'однако',\n",
       "  'пара',\n",
       "  'qw',\n",
       "  'открытый',\n",
       "  'открытие',\n",
       "  'километр',\n",
       "  'массивный',\n",
       "  'представимый',\n",
       "  'вероятность',\n",
       "  'друг',\n",
       "  'автор']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trank_kw = []\n",
    "for i in range(9):\n",
    "    trank_kw_list = []\n",
    "    trank_kw_res = keywords.keywords(normalize_text(all_texts[i]), language='russian', additional_stopwords=stop, scores=True)\n",
    "    for res in trank_kw_res:\n",
    "        if res[1] > 0.1:\n",
    "            trank_kw_list.append(res[0])\n",
    "    all_trank_kw.append(trank_kw_list)\n",
    "all_trank_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_norm = []\n",
    "for i in range(9):\n",
    "    all_texts_norm.append(normalize_text(all_texts[i]))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(all_texts_norm)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['галактика', 'карлик', 'карликовый', 'год', 'млечный', 'обнаружить', 'sdss'],\n",
       " ['вращение', '7b', 'hat', 'орбита'],\n",
       " ['ядро', 'жизнь', 'планета', 'мир'],\n",
       " ['магнитный', 'полюс', 'северный', 'сибирь', 'год', 'последний'],\n",
       " ['снимка', 'сатурн', 'сделать', 'сияние'],\n",
       " ['парус', 'аппарат', 'солнечный', 'космос', 'развернуть'],\n",
       " ['расстояние', 'параллакс', 'рукав', 'метод', 'галактика', 'измерить'],\n",
       " ['квазар', 'галактика', '2958', 'he0450', 'дыра', 'чёрный'],\n",
       " ['пояс',\n",
       "  'друг',\n",
       "  'койперо',\n",
       "  'объект',\n",
       "  'компонент',\n",
       "  'гравитационный',\n",
       "  'масса',\n",
       "  'пара']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tfidf_kw = []\n",
    "df_dict = df.to_dict()\n",
    "keys = list(df_dict)\n",
    "for i in range(9):\n",
    "    tfidf_kw = []\n",
    "    dict_word_n = collections.Counter()\n",
    "    for key in keys:\n",
    "        dict_word_n[key] = df_dict[key][i]\n",
    "    for res in dict_word_n.most_common(10):\n",
    "        if res[1] > 0.153:\n",
    "            if res[0] not in stop:\n",
    "                tfidf_kw.append(res[0])\n",
    "    all_tfidf_kw.append(tfidf_kw)\n",
    "all_tfidf_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "#### Шаблоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_kws_norm\n",
    "# У нас в кс NOUN, ADJ+NOUN, ADJ+VERB, X, X+NOUN. (Не рассматриваем кс>2слов.)\n",
    "shablon = [['NOUN'], ['ADJ', 'NOUN'], ['ADJ', 'VERB'], ['X'], ['X', 'NOUN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy_udpipe.load(\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sorted_rake_kw_pos = []\n",
    "all_sorted_trank_kw_pos = []\n",
    "all_sorted_tfidf_kw_pos = []\n",
    "\n",
    "for i in range(9):\n",
    "    sorted_rake_kw_pos = []\n",
    "    sorted_trank_kw_pos = []\n",
    "    sorted_tfidf_kw_pos = []\n",
    "    \n",
    "    for kw in all_rake_kw[i]:\n",
    "        doc = nlp(kw)\n",
    "        rake_kw_pos = []\n",
    "        for token in doc:\n",
    "            rake_kw_pos.append(token.pos_)\n",
    "        if rake_kw_pos in shablon:\n",
    "            sorted_rake_kw_pos.append([kw, rake_kw_pos])\n",
    "    all_sorted_rake_kw_pos.append(sorted_rake_kw_pos)\n",
    "    \n",
    "    for kw in all_trank_kw[i]:\n",
    "        doc = nlp(kw)\n",
    "        trank_kw_pos = []\n",
    "        for token in doc:\n",
    "            trank_kw_pos.append(token.pos_)\n",
    "        if trank_kw_pos in shablon:\n",
    "            sorted_trank_kw_pos.append([kw, trank_kw_pos])\n",
    "    all_sorted_trank_kw_pos.append(sorted_trank_kw_pos)\n",
    "    \n",
    "    for kw in all_tfidf_kw[i]:\n",
    "        doc = nlp(kw)\n",
    "        tfidf_kw_pos = []\n",
    "        for token in doc:\n",
    "            tfidf_kw_pos.append(token.pos_)\n",
    "        if tfidf_kw_pos in shablon:\n",
    "            sorted_tfidf_kw_pos.append([kw, tfidf_kw_pos])\n",
    "    all_sorted_tfidf_kw_pos.append(sorted_tfidf_kw_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем из эталонных несколько кс, не подходящих по шаблону (давайте считать, что мы их и изначально не выбирали)\n",
    "all_sorted_kws_norm_pos = []\n",
    "\n",
    "for i in range(9):\n",
    "    sorted_kws_norm_pos = []\n",
    "    \n",
    "    for kw in all_kws_norm[i]:\n",
    "        doc = nlp(kw)\n",
    "        kws_norm_pos = []\n",
    "        for token in doc:\n",
    "            kws_norm_pos.append(token.pos_)\n",
    "        if kws_norm_pos in shablon:\n",
    "            sorted_kws_norm_pos.append([kw, kws_norm_pos])\n",
    "    all_sorted_kws_norm_pos.append(sorted_kws_norm_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5\n",
    "\n",
    "Будем оценивать, что получилось..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты Rake, TextRank, TfIDf для каждого текста (без шаблонов)\n",
      "\n",
      "Текст1\t точность\t полнота\t Fмера\n",
      "Rake\t 0.037037037037037035 \t 0.18181818181818182 \t 0.061538461538461535\n",
      "TRank\t 0.18181818181818182 \t 0.18181818181818182 \t 0.18181818181818182\n",
      "TfIDf\t 0.42857142857142855 \t 0.2727272727272727 \t 0.33333333333333326 \n",
      "\n",
      "Текст2\t точность\t полнота\t Fмера\n",
      "Rake\t 0.14285714285714285 \t 0.1111111111111111 \t 0.125\n",
      "TRank\t 0.045454545454545456 \t 0.1111111111111111 \t 0.06451612903225805\n",
      "TfIDf\t 0.25 \t 0.1111111111111111 \t 0.15384615384615383 \n",
      "\n",
      "Текст3\t точность\t полнота\t Fмера\n",
      "Rake\t 0.05405405405405406 \t 0.2857142857142857 \t 0.09090909090909091\n",
      "TRank\t 0.05555555555555555 \t 0.14285714285714285 \t 0.08\n",
      "TfIDf\t 0.25 \t 0.14285714285714285 \t 0.18181818181818182 \n",
      "\n",
      "Текст4\t точность\t полнота\t Fмера\n",
      "Rake\t 0.06666666666666667 \t 0.14285714285714285 \t 0.09090909090909091\n",
      "TRank\t 0.09090909090909091 \t 0.14285714285714285 \t 0.1111111111111111\n",
      "TfIDf\t 0.16666666666666666 \t 0.14285714285714285 \t 0.15384615384615383 \n",
      "\n",
      "Текст5\t точность\t полнота\t Fмера\n",
      "Rake\t 0.0 \t 0.0 \t 0\n",
      "TRank\t 0.23076923076923078 \t 0.42857142857142855 \t 0.3\n",
      "TfIDf\t 0.5 \t 0.2857142857142857 \t 0.36363636363636365 \n",
      "\n",
      "Текст6\t точность\t полнота\t Fмера\n",
      "Rake\t 0.047619047619047616 \t 0.2 \t 0.07692307692307693\n",
      "TRank\t 0.08333333333333333 \t 0.2 \t 0.11764705882352941\n",
      "TfIDf\t 0.2 \t 0.2 \t 0.20000000000000004 \n",
      "\n",
      "Текст7\t точность\t полнота\t Fмера\n",
      "Rake\t 0.07317073170731707 \t 0.3333333333333333 \t 0.12\n",
      "TRank\t 0.08333333333333333 \t 0.1111111111111111 \t 0.09523809523809525\n",
      "TfIDf\t 0.5 \t 0.3333333333333333 \t 0.4 \n",
      "\n",
      "Текст8\t точность\t полнота\t Fмера\n",
      "Rake\t 0.06896551724137931 \t 0.4 \t 0.1176470588235294\n",
      "TRank\t 0.23076923076923078 \t 0.6 \t 0.33333333333333337\n",
      "TfIDf\t 0.3333333333333333 \t 0.4 \t 0.3636363636363636 \n",
      "\n",
      "Текст9\t точность\t полнота\t Fмера\n",
      "Rake\t 0.0 \t 0.0 \t 0\n",
      "TRank\t 0.0 \t 0.0 \t 0\n",
      "TfIDf\t 0.0 \t 0.0 \t 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Результаты Rake, TextRank, TfIDf для каждого текста (без шаблонов)\\n')\n",
    "for i in range(9):\n",
    "    print('Текст' + str(i+1) + '\\t точность\\t полнота\\t Fмера')\n",
    "    \n",
    "    rake_intersect = 0\n",
    "    trank_intersect = 0\n",
    "    tfidf_intersect = 0\n",
    "    \n",
    "    for rake in all_rake_kw[i]:\n",
    "        if rake in all_kws_norm[i]:\n",
    "            rake_intersect += 1\n",
    "    rake_precision = rake_intersect / len(all_rake_kw[i])\n",
    "    rake_recall = rake_intersect / len(all_kws_norm[i])\n",
    "    if rake_intersect == 0:\n",
    "        rake_fm = 0\n",
    "    else:\n",
    "        rake_fm = (2 * rake_precision * rake_recall) / (rake_precision + rake_recall)\n",
    "    print('Rake\\t', rake_precision, '\\t', rake_recall, '\\t', rake_fm)\n",
    "    \n",
    "    for trank in all_trank_kw[i]:\n",
    "        if trank in all_kws_norm[i]:\n",
    "            trank_intersect += 1\n",
    "    trank_precision = trank_intersect / len(all_trank_kw[i])\n",
    "    trank_recall = trank_intersect / len(all_kws_norm[i])\n",
    "    if trank_intersect == 0:\n",
    "        trank_fm = 0\n",
    "    else:\n",
    "        trank_fm = (2 * trank_precision * trank_recall) / (trank_precision + trank_recall)\n",
    "    print('TRank\\t', trank_precision, '\\t', trank_recall, '\\t', trank_fm)\n",
    "    \n",
    "    for tfidf in all_tfidf_kw[i]:\n",
    "        if tfidf in all_kws_norm[i]:\n",
    "            tfidf_intersect += 1\n",
    "    tfidf_precision = tfidf_intersect / len(all_tfidf_kw[i])\n",
    "    tfidf_recall = tfidf_intersect / len(all_kws_norm[i])\n",
    "    if tfidf_intersect == 0:\n",
    "        tfidf_fm = 0\n",
    "    else:\n",
    "        tfidf_fm = (2 * tfidf_precision * tfidf_recall) / (tfidf_precision + tfidf_recall)\n",
    "    print('TfIDf\\t', tfidf_precision, '\\t', tfidf_recall, '\\t', tfidf_fm, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты Rake, TextRank, TfIDf для каждого текста (c шаблонами)\n",
      "\n",
      "Текст1\t точность\t полнота\t Fмера\n",
      "Rake\t 0.125 \t 0.2222222222222222 \t 0.16\n",
      "TRank\t 0.3333333333333333 \t 0.2222222222222222 \t 0.26666666666666666\n",
      "TfIDf\t 0.75 \t 0.3333333333333333 \t 0.46153846153846156 \n",
      "\n",
      "Текст2\t точность\t полнота\t Fмера\n",
      "Rake\t 0.5 \t 0.1111111111111111 \t 0.1818181818181818\n",
      "TRank\t 0.08333333333333333 \t 0.1111111111111111 \t 0.09523809523809525\n",
      "TfIDf\t 0.25 \t 0.1111111111111111 \t 0.15384615384615383 \n",
      "\n",
      "Текст3\t точность\t полнота\t Fмера\n",
      "Rake\t 0.08333333333333333 \t 0.16666666666666666 \t 0.1111111111111111\n",
      "TRank\t 0.09090909090909091 \t 0.16666666666666666 \t 0.11764705882352942\n",
      "TfIDf\t 0.25 \t 0.16666666666666666 \t 0.2 \n",
      "\n",
      "Текст4\t точность\t полнота\t Fмера\n",
      "Rake\t 0.16666666666666666 \t 0.14285714285714285 \t 0.15384615384615383\n",
      "TRank\t 0.3333333333333333 \t 0.14285714285714285 \t 0.2\n",
      "TfIDf\t 0.5 \t 0.14285714285714285 \t 0.22222222222222224 \n",
      "\n",
      "Текст5\t точность\t полнота\t Fмера\n",
      "Rake\t 0.0 \t 0.0 \t 0\n",
      "TRank\t 0.42857142857142855 \t 0.42857142857142855 \t 0.42857142857142855\n",
      "TfIDf\t 0.6666666666666666 \t 0.2857142857142857 \t 0.4 \n",
      "\n",
      "Текст6\t точность\t полнота\t Fмера\n",
      "Rake\t 0.2 \t 0.3333333333333333 \t 0.25\n",
      "TRank\t 0.125 \t 0.3333333333333333 \t 0.18181818181818182\n",
      "TfIDf\t 0.3333333333333333 \t 0.3333333333333333 \t 0.3333333333333333 \n",
      "\n",
      "Текст7\t точность\t полнота\t Fмера\n",
      "Rake\t 0.2727272727272727 \t 0.3333333333333333 \t 0.3\n",
      "TRank\t 0.14285714285714285 \t 0.1111111111111111 \t 0.125\n",
      "TfIDf\t 0.6 \t 0.3333333333333333 \t 0.42857142857142855 \n",
      "\n",
      "Текст8\t точность\t полнота\t Fмера\n",
      "Rake\t 0.18181818181818182 \t 0.4 \t 0.25000000000000006\n",
      "TRank\t 0.3 \t 0.6 \t 0.4\n",
      "TfIDf\t 0.6666666666666666 \t 0.4 \t 0.5 \n",
      "\n",
      "Текст9\t точность\t полнота\t Fмера\n",
      "Rake\t 0.0 \t 0.0 \t 0\n",
      "TRank\t 0.0 \t 0.0 \t 0\n",
      "TfIDf\t 0.0 \t 0.0 \t 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Результаты Rake, TextRank, TfIDf для каждого текста (c шаблонами)\\n')\n",
    "for i in range(9):\n",
    "    print('Текст' + str(i+1) + '\\t точность\\t полнота\\t Fмера')\n",
    "    \n",
    "    rake_intersect = 0\n",
    "    trank_intersect = 0\n",
    "    tfidf_intersect = 0\n",
    "    \n",
    "    for rake in all_sorted_rake_kw_pos[i]:\n",
    "        if rake in all_sorted_kws_norm_pos[i]:\n",
    "            rake_intersect += 1\n",
    "    rake_precision = rake_intersect / len(all_sorted_rake_kw_pos[i])\n",
    "    rake_recall = rake_intersect / len(all_sorted_kws_norm_pos[i])\n",
    "    if rake_intersect == 0:\n",
    "        rake_fm = 0\n",
    "    else:\n",
    "        rake_fm = (2 * rake_precision * rake_recall) / (rake_precision + rake_recall)\n",
    "    print('Rake\\t', rake_precision, '\\t', rake_recall, '\\t', rake_fm)\n",
    "    \n",
    "    for trank in all_sorted_trank_kw_pos[i]:\n",
    "        if trank in all_sorted_kws_norm_pos[i]:\n",
    "            trank_intersect += 1\n",
    "    trank_precision = trank_intersect / len(all_sorted_trank_kw_pos[i])\n",
    "    trank_recall = trank_intersect / len(all_sorted_kws_norm_pos[i])\n",
    "    if trank_intersect == 0:\n",
    "        trank_fm = 0\n",
    "    else:\n",
    "        trank_fm = (2 * trank_precision * trank_recall) / (trank_precision + trank_recall)\n",
    "    print('TRank\\t', trank_precision, '\\t', trank_recall, '\\t', trank_fm)\n",
    "    \n",
    "    for tfidf in all_sorted_tfidf_kw_pos[i]:\n",
    "        if tfidf in all_sorted_kws_norm_pos[i]:\n",
    "            tfidf_intersect += 1\n",
    "    tfidf_precision = tfidf_intersect / len(all_sorted_tfidf_kw_pos[i])\n",
    "    tfidf_recall = tfidf_intersect / len(all_sorted_kws_norm_pos[i])\n",
    "    if tfidf_intersect == 0:\n",
    "        tfidf_fm = 0\n",
    "    else:\n",
    "        tfidf_fm = (2 * tfidf_precision * tfidf_recall) / (tfidf_precision + tfidf_recall)\n",
    "    print('TfIDf\\t', tfidf_precision, '\\t', tfidf_recall, '\\t', tfidf_fm, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6\n",
    "\n",
    "Я выбрала (из любопытства и желания почитать что-то астрономическое) очень специфические тексты об исследованиях космоса, поэтому не сильно удивлена, что так много ошибок и такие низкие показатели.\n",
    "\n",
    "Конечно, с шаблонами точность улучшилась, потому что мы откинули заведомо неправильные ключевые сочетания. Убрали глаголы, сочетания, которые редко бывают кс и т.д.\n",
    "\n",
    "Без шаблонов совсем грустно получилось. Можно было бы ещё понастраивать параметры (попробовать обрезать список кс в других местах), я обрезала по последнее найденное кс для одного из девяти текстов.\n",
    "\n",
    "Лучше всего почти везде себя проявил TfIDf, но серьёзным минусом способа является то, что на выходе получались только односложные кс. Один из простых и самых действенных способов улучшения показателей: сделать TfIDf не только для отдельных слов, но и для биграмм. А ещё этому методу немного помешало, что кс в текстах иногда пересекались и метод не чувствовал из-за этого текстовой уникальности словосочетания.\n",
    "\n",
    "Чуть хуже получились результаты у TextRake, ещё хуже у Rake. Возможно, можно было создавать список-эталон немного по-другому, тогда бы результаты получились бы лучше. Как их работу улучшить на моих текстах - поизменять, сколько обрезать, потерять часть правильно найденных кс, но улучшить точность для остальных.\n",
    "\n",
    "Совсем ничего не нашлось для 9ого текста. Проблема в том, что кс не повторяются много раз. В итоге нашлось много других слов, а нужные кс не нашлись. TfIDf был бы близок, если бы были биграммы.\n",
    "\n",
    "TextRake и Rake дают слишком простые слова и словосочетания, в то время как кс у меня - слова специальные, специфические. Можно было бы к ним добавить фильтр на \"особенность\" (который есть у TfIDf, особенно, если сравнивать не только с другими моими текстами, но и с чем-нибудь попроще)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
